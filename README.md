# GRU-L2O-with-Mathematical-Structure
We publish simulation data as experiments to facilitate reproducible research and fair benchmarking in the L2O domain.
Paper：Learning to optimize based on rate decay, The Computer Journal, https://doi.org/10.1093/comjnl/bxaf012
### 1. Some limitations of L2O
Generalization ability: The trained optimization strategy may overfit specific problems, leading to poor performance on new tasks. 

Structural variations: L2O is flexible, but differences in structure among various optimization problems can affect optimization performance.
### 2. Contributions：
GRU: Innovatively utilizing the lighter and more efficient GRU neural network as the core component of the L2O model.

Mathematics-inspired update rule structure: Further enhancing the mathematics-inspired update rule structure aims to improve the performance of the L2O model in convex function optimization.
